{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb0b675",
   "metadata": {},
   "source": [
    "<div align=\"middle\">\n",
    "  <h1><b><i>تمرین سوم</i></b></h1>\n",
    " </div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b305c09",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "   #  بخش اول:  هدوپ \n",
    "\n",
    "    ۱- به سوالات زیر پاسخ دهید\n",
    "    - مفهوم replication جیست\n",
    "    - مفهوم block در HDFS چیست و اگر بلاک‌ها را بسیار کوچک درنظر بگیریم چه مشکلی پیش می‌آید\n",
    "    \n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a71f1",
   "metadata": {},
   "source": [
    "    # ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb7f81",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "\n",
    "    ۲- در  این قسمت شما باید ابتدا دیتاست داده شده را از حالت فشرده در بیاورید و سپس فایل‌های درون آن را در کلاستر هدوپ در مسیر /homework3/dataset/ بارگزاری کنید \n",
    "    نکته: در این بخش دستورات زده شده خود را برای کار با hdfs  در ترمینال را در سلول زیر وارد نمایید\n",
    "    برای دسترسی به کامند میتوانید وارد یکی از کانتینر‌های هدوپ شوید و دستور را اجرا کنید همچنین همه کانتینر‌ها دارای shared_dir\n",
    "    در روت خود هستند و این دایرکتوری در تمام کانتینر‌ها به اشتراک گذاشته شده است\n",
    "    برای چک کردن فایل‌ها در hdfs به \n",
    "    \n",
    "[HDFS webUI](http://localhost:9870/explorer.html#/)\n",
    "    \n",
    "    مراجعه کنید\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189f9b0",
   "metadata": {},
   "source": [
    "    # ToDo\n",
    "    # your-hdfs-commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254df80",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661db19",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "   #  بخش دوم:  اسپارک \n",
    "\n",
    "    ۱- به سوالات زیر پاسخ دهید\n",
    "    - مزیت اسپارک نسبت به مدل قدیمی map/reduce چیست؟\n",
    "    -  تفاوت action و transform در اسپارک چیست؟\n",
    "    \n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b0b1f",
   "metadata": {},
   "source": [
    "    # ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589646c9",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "\n",
    "    ۲- کد‌های خواسته شده در قسمت‌های پایینی را تکمیل کنید\n",
    "    (قسمت های ToDo )\n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365d78f",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "##  اتصال به کلاستر اسپارک و هدوپ \n",
    "\n",
    "    در این قسمت از تمرین باید به عنوان درایور یک سسشن  به کلاستر اسپارک بسازیم.\n",
    " </div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b11061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import *\n",
    "import math\n",
    "import pandas , numpy\n",
    "import matplotlib\n",
    "import pprint\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208c06c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.20.30.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>homework3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5704403520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"homework3\").master(\"spark://spark-master:7077\").config(\"fs.defaultFS\",\"hdfs://namenode:9000/\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f93b9",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "#  خواندن داده \n",
    "\n",
    "    :در اسپارک ما ساختارهای مختلفی برای کار با داده و پخش شدن آن‌ها در شبکه داریم که به ۳ دسته تقسیم بندی میشوند \n",
    "+ RDD\n",
    "+ Dataset\n",
    "+ DataFrame\n",
    "    \n",
    "    \n",
    "     برای مطالعه بیشتر به لینک زیر مراجعه کنید:\n",
    "[rdd-vs-dataframe-vs-dataset](https://phoenixnap.com/kb/rdd-vs-dataframe-vs-dataset)\n",
    "\n",
    "    ما در درس با ساختار RDD آشنا شدیم حال در این تمرین میخواهیم با ساختار Dataframe آشنا شویم و به کمک آن دیتا را از روی HDFS بخوانیم و روی آن فایل‌ها پردازش انجام دهیم\n",
    " \n",
    " </div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68f0e2",
   "metadata": {},
   "source": [
    "- [Spark Cluster Master UI](http://localhost:8080/)\n",
    "- [Spark UI](http://localhost:4040)\n",
    "- [Web Hdfs](http://localhost:9870/explorer.html#/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae4f4c",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " .در این قسمت دیتاست را لود می‌کنیم \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4939ddb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "War = spark.read.json(f\"/homework3/dataset/War.json\")\n",
    "Weapon = spark.read.json(\"/homework3/dataset/Weapon.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af9f38",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "برای اینکه بتوانیم روی دیتای لود شده به وسیله تابع  spark.sql\n",
    "    کوئری‌های SQL بزنیم\n",
    "    باید دو دیتاست لود شده را به عنوان table\n",
    "    به spark \n",
    "    معرفی کنیم\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f85430",
   "metadata": {},
   "outputs": [],
   "source": [
    "War.registerTempTable(\"War\")\n",
    "Weapon.registerTempTable(\"Weapon\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1988be",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "یک مثال ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67118144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "|  DateOfWar|DurationOfWar|Location|MinorityStart|TargetMinority|      Weapon|\n",
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "|73298-04-22|       1005.0|BIEN HOA|          Elf|           Orc|Mirkwood Bow|\n",
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM War where DurationOfWar=1005.0 limit 1;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dad2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "|  DateOfWar|DurationOfWar|    Location|MinorityStart|TargetMinority|      Weapon|\n",
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "|73361-06-05|       1005.0|TAN SON NHUT|          Elf|           Orc|Belthronding|\n",
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "War.select(\"*\").filter(col(\"DurationOfWar\")==1005.0).limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6eea7c",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " ده رکورد آخر را نمایش دهید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "pprint.pprint(Weapon.take(10))\n",
    "print(\"**\"*10)\n",
    "pprint.pprint(War.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb25934",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "اسکیما یا ساختار دیتاست ها را نمایش دهید\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ad965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "War.printSchema()\n",
    "Weapon.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be8c23",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006f90a",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " چه تعداد نبرد در این مدت انجام شده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55d53b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ToDo\n",
    "print(f\"Number of all Wars is {War.count()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225850a2",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbd137",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "هر نژاد در کدام و چه تعدادی نبرد مشارکت داشته اند  به صورت مرتب شده نمایش دهبد؟\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "mostWar = War.groupBy(\"MinorityStart\").count().sort(desc(\"count\"))\n",
    "mostWar.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64dd81c",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6f33d",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "نمودار تعداد نبرد بر اساس نژاد را نمایش دهید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44458f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "query = \"\"\"\n",
    "SELECT MinorityStart, count(*) as Minority\n",
    "FROM War\n",
    "GROUP BY MinorityStart\n",
    "ORDER BY Minority DESC\n",
    "\"\"\"\n",
    "\n",
    "mostWarPD = spark.sql(query).toPandas()\n",
    "\n",
    "pl = mostWarPD.plot(kind=\"bar\",  x=\"MinorityStart\", y=\"Minority\",\n",
    "                            figsize=(10, 7), log=True, alpha=0.5, color=\"blue\")\n",
    "pl.set_xlabel(\"Minority\")\n",
    "pl.set_ylabel(\"Number of War\")\n",
    "pl.set_title(\"Number of War by Minority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1d29d",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/plotlib.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04446cd",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "چه تعداد نبردهایی بر اساس زمان انجام شده بر اساس زمان مرتب کنید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f26bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "spark.sql(\"select DateOfWar , count(*) as count from War group by DateOfWar order by DateOfWar\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77c932",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/date_groupBy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83d603",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "نژاد \"اورک\" توسط چه نژادی مورد حمله قرار گرفته است ؟\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "spark.sql(\"select MinorityStart  from War where TargetMinority='Orc' group by MinorityStart\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43ad31",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/orc_target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285f2a1",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "    بیشترین سلاحی که در این جنگ ها استفاده شده کدام سلاح  بوده است؟.\n",
    "    جزییات این سلاح را از فایل مشخصات سلاح (Weapon) می‌توانید بدست آورید.\n",
    "    فایل مربوط به سلاح ها را بازخوانی کرده و برای نمایش بین دو فایل از join استفاده شود.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "\n",
    "w1 = War.groupBy(\"Weapon\").agg(count(\"*\").alias(\"MissionsCount\"))\n",
    "w1.join(Weapon, w1.Weapon == Weapon.Weapon ).drop(Weapon.Weapon).sort(desc(\"MissionsCount\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb63a9e",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/most_used_weapons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b0dab",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "# تابع تعریف شده توسط کاربر(UDF)\n",
    "\n",
    "    یکی از مزایای اسپارک این است که نه تنها برای ما یک زبان SQL فراهم کرده که روی چندین سرور به صورت همزمان پردازش را انجام دهد بلکه \n",
    "    میتوان به زبان‌های مختلف توابعی تعریف کرد که روی  همه executor ها اجرا شود\n",
    "    در این بخش از شما انتظار می‌رود که با نوشتن یک UDF به زبان پایتونی \n",
    "    توضیحات هر اسلحه را به 3 کلمه اول آن کوتاه کنید و بقیه کلمات را حذف کنید و سوتونی به نام short_description را به داده های \n",
    "    Weapon اضافه کنید\n",
    "    \n",
    "    \n",
    " </div>\n",
    " \n",
    "[pyspark.sql.functions.udf](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.functions.udf.html)\n",
    "\n",
    "[pyspark.sql.DataFrame.withColumn](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "\n",
    "@udf\n",
    "def shortener(text:str):\n",
    "    return \" \".join(text.split()[:3])\n",
    "\n",
    "Weapon.withColumn(\"short_description\",shortener(col(\"Description\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0253e1e",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/shortener_udf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5e40d",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "# نوشتن داده و پارتیشنینگ\n",
    "    زمانی که میخواهیم داده های حجیم را به صورت فایل هایی ذخیره کنیم  نمیتوانیم همه داده را در یک فایل بزرگ ذخیره کنیم به چند دلیل :\n",
    "-  ذخیره سازی یک فایل بزرگ باعث ؛تنها نقطه شکست میشود؛ و با حذف آن کل داده از دست میرود\n",
    "- جستجو در این یک فایل بزرگ که مرتب شده نیست دشوار و عملی نیست\n",
    "- آپدیت کردن سخت تر میشود\n",
    "پس تا حدودی حل این میشکل از راه حل های زیر استفاده میکنیم\n",
    "# پارتیشنینگ: \n",
    "-     بر اساس یک فیلد داده هارا دسته بندی میکنیم و در دایرکتوری های مختلف میریزیم این کار را اسپارک برای ما انجام میدهد\n",
    "\n",
    "    \n",
    " </div>\n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0660d1",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"rtl\">\n",
    "\n",
    "    در این بخش شما باید یک دیتاست کامل بسازید بدین شکل که دیتاست War و Weapon\n",
    "     را با یکدیگر جوین کنید سپس همه آن رکورد‌هایی که  در توضیحات اسلحه آنها کلمه sword \n",
    "    نیامده است را فیلتر کرده و برا اساس گونه شروع کننده جنگ (MinorityStart) پارتیشن کنید\n",
    "    و روی HDFS\n",
    "      در مسیر /homework3/<student_number>/output/war_without_sword بنویسید\n",
    "    و ۲۰ رکورد اول آن را نمایش دهید\n",
    "    توجه کنید فایل‌های خروجی باید از نوع JSON باشند\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "[pyspark.sql.DataFrameWriter.partitionBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.partitionBy.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543baca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ToDo\n",
    "temp_df = War.join(Weapon, War.Weapon == Weapon.Weapon ).drop(Weapon.Weapon).filter(~ col(\"Description\").contains(\"sword\"))\n",
    "temp_df.show()\n",
    "temp_df.write.partitionBy(\"MinorityStart\").json(\"/homework3/9731056/output/war_without_sword\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459519de",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![war without sword](expected_answers/war_without_sword.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51030fd5",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"rtl\">\n",
    "    \n",
    "  ### گزارش HDFS\n",
    "    با مراجعه به HDFS UI\n",
    "    خروجی پارتیشن شده مسیر بالا را مشاهده میکنید\n",
    "     -تعداد دایرکتوری‌های ایجاد شده چندتاست و دلیل آن چیست؟ \n",
    "    -در هر دایرکتوری ایجاد شده چند فایل JSON میبینید و دلیل تعدد این فایل‌ها چیست؟\n",
    "    - چگونه میتوان از اسپارک خواست تا از تعدد این فایل‌ها جلوگیری کند و یک فایل در این مسیر‌ها بریزد؟\n",
    "    - coalesce و repartition  در اسپارک چیستند و کاربر اصلی آنها چیست؟\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591aa058",
   "metadata": {},
   "source": [
    "    # ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0864c99",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"rtl\">\n",
    "\n",
    "   ## coalesce\n",
    "    همان تسک بالا را انجام دهید  ولی  سعی کنید در هر دایرکتوری پارتیشن شده تنها یک فایل JSON ریخته شود.\n",
    "    نکته:  در مسیر جدید زیر آن را بنویسید.\n",
    "    /homework3/<student_number>/output/war_without_sword_v2/\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "[pyspark.sql.DataFrame.coalesce](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.coalesce.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "temp_df = War.join(Weapon, War.Weapon == Weapon.Weapon ).drop(Weapon.Weapon).filter(~ col(\"Description\").contains(\"sword\"))\n",
    "temp_df.show()\n",
    "temp_df.coalesce(1).write.partitionBy(\"MinorityStart\").json(\"/homework3/9731056/output/war_without_sword_v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821317d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8e878d",
   "metadata": {},
   "source": [
    "<div align=\"middle\">\n",
    "  <h1><b><i>تمرین سوم</i></b></h1>\n",
    " </div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5210820",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "   #  بخش اول:  هدوپ \n",
    "\n",
    "    ۱- به سوالات زیر پاسخ دهید\n",
    "    - مفهوم replication جیست\n",
    "    - مفهوم block در HDFS چیست و اگر بلاک‌ها را بسیار کوچک درنظر بگیریم چه مشکلی پیش می‌آید\n",
    "    \n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432970db",
   "metadata": {},
   "source": [
    "    # ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d7cb2",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "\n",
    "    ۲- در  این قسمت شما باید ابتدا دیتاست داده شده را از حالت فشرده در بیاورید و سپس فایل‌های درون آن را در کلاستر هدوپ در مسیر /homework3/dataset/ بارگزاری کنید \n",
    "    نکته: در این بخش دستورات زده شده خود را برای کار با hdfs  در ترمینال را در سلول زیر وارد نمایید\n",
    "    برای دسترسی به کامند میتوانید وارد یکی از کانتینر‌های هدوپ شوید و دستور را اجرا کنید همچنین همه کانتینر‌ها دارای shared_dir\n",
    "    در روت خود هستند و این دایرکتوری در تمام کانتینر‌ها به اشتراک گذاشته شده است\n",
    "    برای چک کردن فایل‌ها در hdfs به \n",
    "    \n",
    "[HDFS webUI](http://10.20.30.11:9870/explorer.html#/)\n",
    "    \n",
    "    مراجعه کنید\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384fcbd6",
   "metadata": {},
   "source": [
    "    # ToDo\n",
    "    # your-hdfs-commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3a971",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e7de9",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "   #  بخش دوم:  اسپارک \n",
    "\n",
    "    ۱- به سوالات زیر پاسخ دهید\n",
    "    - مزیت اسپارک نسبت به مدل قدیمی map/reduce چیست؟\n",
    "    -  تفاوت action و transform در اسپارک چیست؟\n",
    "    \n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754c72f",
   "metadata": {},
   "source": [
    "    # ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48daeb03",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "    \n",
    "\n",
    "    ۲- کد‌های خواسته شده در قسمت‌های پایینی را تکمیل کنید\n",
    "    (قسمت های ToDo )\n",
    "</div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673ae0b",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "##  اتصال به کلاستر اسپارک و هدوپ \n",
    "\n",
    "    در این قسمت از تمرین باید به عنوان درایور یک سسشن  به کلاستر اسپارک بسازیم.\n",
    " </div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7667426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import *\n",
    "import math\n",
    "import pandas , numpy\n",
    "import matplotlib\n",
    "import pprint\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd8aa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.20.30.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>homework3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fee20ff2520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"homework3\").master(\"spark://spark-master:7077\").config(\"fs.defaultFS\",\"hdfs://namenode:9000/\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a98d1",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "#  خواندن داده \n",
    "\n",
    "    :در اسپارک ما ساختارهای مختلفی برای کار با داده و پخش شدن آن‌ها در شبکه داریم که به ۳ دسته تقسیم بندی میشوند \n",
    "+ RDD\n",
    "+ Dataset\n",
    "+ DataFrame\n",
    "    \n",
    "    \n",
    "     برای مطالعه بیشتر به لینک زیر مراجعه کنید:\n",
    "[rdd-vs-dataframe-vs-dataset](https://phoenixnap.com/kb/rdd-vs-dataframe-vs-dataset)\n",
    "\n",
    "    ما در درس با ساختار RDD آشنا شدیم حال در این تمرین میخواهیم با ساختار Dataframe آشنا شویم و به کمک آن دیتا را از روی HDFS بخوانیم و روی آن فایل‌ها پردازش انجام دهیم\n",
    " \n",
    " </div>\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfd294",
   "metadata": {},
   "source": [
    "- [Spark Cluster Master UI](http://10.20.30.31:8080/)\n",
    "- [Spark UI](http://10.20.30.100:4040)\n",
    "- [Web Hdfs](http://10.20.30.11:9870/explorer.html#/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a51b19",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " .در این قسمت دیتاست را لود می‌کنیم \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d241b19",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "War = spark.read.json(f\"/homework3/dataset/War.json\")\n",
    "Weapon = spark.read.json(\"/homework3/dataset/Weapon.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce56ffb",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "برای اینکه بتوانیم روی دیتای لود شده به وسیله تابع  spark.sql\n",
    "    کوئری‌های SQL بزنیم\n",
    "    باید دو دیتاست لود شده را به عنوان table\n",
    "    به spark \n",
    "    معرفی کنیم\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b3860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "War.registerTempTable(\"War\")\n",
    "Weapon.registerTempTable(\"Weapon\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63751e",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "یک مثال ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3254f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "|  DateOfWar|DurationOfWar|Location|MinorityStart|TargetMinority|      Weapon|\n",
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "|73298-04-22|       1005.0|BIEN HOA|          Elf|           Orc|Mirkwood Bow|\n",
      "+-----------+-------------+--------+-------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM War where DurationOfWar=1005.0 limit 1;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec2ab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "|  DateOfWar|DurationOfWar|    Location|MinorityStart|TargetMinority|      Weapon|\n",
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "|73361-06-05|       1005.0|TAN SON NHUT|          Elf|           Orc|Belthronding|\n",
      "+-----------+-------------+------------+-------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "War.select(\"*\").filter(col(\"DurationOfWar\")==1005.0).limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273297",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " ده رکورد آخر را نمایش دهید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "pprint.pprint(Weapon.take(10))\n",
    "print(\"**\"*10)\n",
    "pprint.pprint(War.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a6739",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "اسکیما یا ساختار دیتاست ها را نمایش دهید\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "War.printSchema()\n",
    "Weapon.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941bc0d9",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225ca99",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    " چه تعداد نبرد در این مدت انجام شده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97efb1f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ToDo\n",
    "print(f\"Number of all Wars is {War.count()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78072732",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af05b8",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "هر نژاد در کدام و چه تعدادی نبرد مشارکت داشته اند  به صورت مرتب شده نمایش دهبد؟\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e33d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "mostWar = War.groupBy(\"MinorityStart\").count().sort(desc(\"count\"))\n",
    "mostWar.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d68f8",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8b6d0",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "نمودار تعداد نبرد بر اساس نژاد را نمایش دهید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63425f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "query = \"\"\"\n",
    "SELECT MinorityStart, count(*) as Minority\n",
    "FROM War\n",
    "GROUP BY MinorityStart\n",
    "ORDER BY Minority DESC\n",
    "\"\"\"\n",
    "\n",
    "mostWarPD = spark.sql(query).toPandas()\n",
    "\n",
    "pl = mostWarPD.plot(kind=\"bar\",  x=\"MinorityStart\", y=\"Minority\",\n",
    "                            figsize=(10, 7), log=True, alpha=0.5, color=\"blue\")\n",
    "pl.set_xlabel(\"Minority\")\n",
    "pl.set_ylabel(\"Number of War\")\n",
    "pl.set_title(\"Number of War by Minority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f12b90d",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/plotlib.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374cc42",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "چه تعداد نبردهایی بر اساس زمان انجام شده بر اساس زمان مرتب کنید\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9734b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "spark.sql(\"select DateOfWar , count(*) as count from War group by DateOfWar order by DateOfWar\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71861d2",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/date_groupBy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5abe35",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "نژاد \"اورک\" توسط چه نژادی مورد حمله قرار گرفته است ؟\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "spark.sql(\"select MinorityStart  from War where TargetMinority='Orc' group by MinorityStart\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd2aee",
   "metadata": {},
   "source": [
    "### Expected\n",
    "![image](expected_answers/orc_target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0026d",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "بیشترین سلاحی که در این جنگ ها استفاده شده کدام سلاح بوده.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64814c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "War.groupBy(\"Weapon\").agg(count(\"*\").alias(\"MissionsCount\"))\\\n",
    "                  .sort(desc(\"MissionsCount\"))\\\n",
    "                  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee0a06",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"auto\">\n",
    "جزییات این سلاح را از فایل مشخصات سلاح نمایش دهید.<br>\n",
    "فایل مربوط به سلاح ها را بازخوانی کرده و برای نمایش بین دو فایل از join استفاده شود.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "w1 = War.groupBy(\"Weapon\").agg(count(\"*\").alias(\"MissionsCount\"))\n",
    "w1.join(Weapon, w1.Weapon == Weapon.Weapon ).drop(Weapon.Weapon).sort(desc(\"MissionsCount\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5364b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f75327",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd40140",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"right\" dir=\"auto\">\n",
    "   \n",
    "# نوشتن داده و پارتیشنینگ\n",
    "    زمانی که میخواهیم داده های حجیم را به صورت فایل هایی ذخیره کنیم  نمیتوانیم همه داده را در یک فایل بزرگ ذخیره کنیم به چند دلیل :\n",
    "-  ذخیره سازی یک فایل بزرگ باعث ؛تنها نقطه شکست میشود؛ و با حذف آن کل داده از دست میرود\n",
    "- جستجو در این یک فایل بزرگ که مرتب شده نیست دشوار و عملی نیست\n",
    "- آپدیت کردن سخت تر میشود\n",
    "پس تا حدودی حل این میشکل از راه حل های زیر استفاده میکنیم\n",
    "# پارتیشنینگ: \n",
    "-     بر اساس یک فیلد داده هارا دسته بندی میکنیم و در دایرکتوری های مختلف میریزیم این کار را اسپارک برای ما انجام میدهد\n",
    "\n",
    "    \n",
    " </div>\n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2e116",
   "metadata": {},
   "source": [
    "<div align=\"right\" dir=\"rtl\">\n",
    "برای افزایش امنیت گزارش این مهم است تا بتوان از طریقی دشمن را دچار سردرگمی کرد تا درصورتی که بروز نفوذ امنیت تا حدودی حفظ شود.\n",
    "از روی دیتاست موجود یک نسخه ایجاد کنید و در آن اورک ها را به عنوان بیشترین حمله کننده تعیین کنید. دیتاست جدید را با فرمت جی‌سان ذخیره کرده و نتیجه را گزارش دهید.\n",
    "</div>\n",
    "\n",
    "[pyspark.sql.DataFrameWriter.partitionBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.partitionBy.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870d80",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_json = War.withColumn('MinorityStart',\n",
    "                       when(War.MinorityStart == \"Elf\", regexp_replace(War.MinorityStart, 'Elf', 'Orc'))\n",
    "                       .when(War.MinorityStart.startswith(\"Orc\"), regexp_replace(War.MinorityStart, 'Orc', 'Elf'))\n",
    "                       ).coalesce(1).write.format('json').save('dataset/new_war_report.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57068be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_war =  spark.read.json(\"dataset/new_war_report.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae3bc7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_war.groupBy(\"MinorityStart\").count().sort(desc(\"count\")) .toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
